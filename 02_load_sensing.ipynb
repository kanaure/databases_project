{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8752ef69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Setup complete\n"
     ]
    }
   ],
   "source": [
    "#setup + imports\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from config import engine\n",
    "\n",
    "# Helper function to extract uid from filename\n",
    "def extract_uid(filename):\n",
    "    \"\"\"Extract uid from filenames like 'activity_u01.csv' -> 'u01'\"\"\"\n",
    "    match = re.search(r'u\\d+', filename)\n",
    "    return match.group() if match else None\n",
    "\n",
    "print(\"✓ Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b5aed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 49 total unique students across all files\n",
      "UIDs found: ['u00', 'u01', 'u02', 'u03', 'u04', 'u05', 'u07', 'u08', 'u09', 'u10', 'u12', 'u13', 'u14', 'u15', 'u16', 'u17', 'u18', 'u19', 'u20', 'u22', 'u23', 'u24', 'u25', 'u27', 'u30', 'u31', 'u32', 'u33', 'u34', 'u35', 'u36', 'u39', 'u41', 'u42', 'u43', 'u44', 'u45', 'u46', 'u47', 'u49', 'u50', 'u51', 'u52', 'u53', 'u54', 'u56', 'u57', 'u58', 'u59']\n",
      "\n",
      "Adding 19 new students: ['u00', 'u03', 'u13', 'u20', 'u23', 'u31', 'u34', 'u35', 'u36', 'u39', 'u42', 'u44', 'u45', 'u47', 'u50', 'u51', 'u53', 'u56', 'u58']\n",
      "✓ Successfully added 19 new students\n",
      "\n",
      "Total students now in database: 49\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load students from all sources (grades + sensing files)\n",
    "\n",
    "def load_all_students():\n",
    "    \"\"\"Extract ALL unique uids from every data source\"\"\"\n",
    "    all_uids = set()\n",
    "    \n",
    "    # From sensing files (extract from filenames)\n",
    "    sensing_dirs = ['activity', 'audio', 'bluetooth', 'conversation', 'dark', \n",
    "                    'gps', 'phonecharge', 'phonelock', 'wifi', 'wifi_location']\n",
    "    \n",
    "    for subdir in sensing_dirs:\n",
    "        dir_path = f'/Users/test/Downloads/Data Management & Databases/studentlife_project/data/sensing/{subdir}'\n",
    "        if os.path.exists(dir_path):\n",
    "            for filename in os.listdir(dir_path):\n",
    "                uid = extract_uid(filename)\n",
    "                if uid:\n",
    "                    all_uids.add(uid)\n",
    "    \n",
    "    # From behavioral files\n",
    "    for folder in ['sms', 'call_log', 'app_usage', 'calendar', 'dinning']:\n",
    "        dir_path = f'../data/{folder}'\n",
    "        if os.path.exists(dir_path):\n",
    "            for filename in os.listdir(dir_path):\n",
    "                uid = extract_uid(filename)\n",
    "                if uid:\n",
    "                    all_uids.add(uid)\n",
    "    \n",
    "    print(f\"Found {len(all_uids)} total unique students across all files\")\n",
    "    print(f\"UIDs found: {sorted(all_uids)}\")\n",
    "    \n",
    "    # Check what's already in database\n",
    "    existing = pd.read_sql(\"SELECT uid FROM student\", engine)\n",
    "    existing_uids = set(existing['uid'].tolist())\n",
    "    \n",
    "    # Find new ones to add\n",
    "    new_uids = all_uids - existing_uids\n",
    "    \n",
    "    if new_uids:\n",
    "        print(f\"\\nAdding {len(new_uids)} new students: {sorted(new_uids)}\")\n",
    "        new_students = pd.DataFrame({'uid': sorted(new_uids)})\n",
    "        new_students.to_sql('student', engine, if_exists='append', index=False)\n",
    "        print(f\"✓ Successfully added {len(new_uids)} new students\")\n",
    "    else:\n",
    "        print(f\"✓ All {len(all_uids)} students already in database\")\n",
    "    \n",
    "    # Verify final count\n",
    "    final = pd.read_sql(\"SELECT COUNT(*) as count FROM student\", engine)\n",
    "    print(f\"\\nTotal students now in database: {final['count'][0]}\")\n",
    "    \n",
    "    return len(all_uids)\n",
    "\n",
    "load_all_students()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15117c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 22,842,191 activity readings from 49 students\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22842191"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Activity data\n",
    "\n",
    "def load_activity_data():\n",
    "    \"\"\"Load all activity reading files\"\"\"\n",
    "    activity_dir = '/Users/test/Downloads/Data Management & Databases/studentlife_project/data/sensing/activity'\n",
    "    all_frames = []\n",
    "    \n",
    "    for filename in os.listdir(activity_dir):\n",
    "        if not filename.endswith('.csv'):\n",
    "            continue\n",
    "        \n",
    "        uid = extract_uid(filename)\n",
    "        if not uid:\n",
    "            print(f\"⚠ Skipping {filename} - no uid found\")\n",
    "            continue\n",
    "        \n",
    "        filepath = os.path.join(activity_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['uid'] = uid\n",
    "        \n",
    "        # Fix column names (remove leading spaces)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        # Rename to match schema\n",
    "        df = df.rename(columns={'activity inference': 'activity_inference'})\n",
    "        \n",
    "        all_frames.append(df)\n",
    "    \n",
    "    # Combine all students\n",
    "    combined = pd.concat(all_frames, ignore_index=True)\n",
    "    \n",
    "    # Load to database\n",
    "    combined.to_sql('activity_reading', engine, if_exists='append', index=False)\n",
    "    \n",
    "    print(f\"✓ Loaded {len(combined):,} activity readings from {len(all_frames)} students\")\n",
    "    return len(combined)\n",
    "\n",
    "load_activity_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fe145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Audio data\n",
    "\n",
    "def load_audio_data():\n",
    "    \"\"\"Load all audio reading files\"\"\"\n",
    "    audio_dir = '/Users/test/Downloads/Data Management & Databases/studentlife_project/data/sensing/audio'\n",
    "    all_frames = []\n",
    "    \n",
    "    for filename in os.listdir(audio_dir):\n",
    "        if not filename.endswith('.csv'):\n",
    "            continue\n",
    "        \n",
    "        uid = extract_uid(filename)\n",
    "        if not uid:\n",
    "            continue\n",
    "        \n",
    "        filepath = os.path.join(audio_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['uid'] = uid\n",
    "        \n",
    "        # Fix column names\n",
    "        df.columns = df.columns.str.strip()\n",
    "        df = df.rename(columns={'audio inference': 'audio_inference'})\n",
    "        \n",
    "        all_frames.append(df)\n",
    "    \n",
    "    combined = pd.concat(all_frames, ignore_index=True)\n",
    "    combined.to_sql('audio_reading', engine, if_exists='append', index=False)\n",
    "    \n",
    "    print(f\"✓ Loaded {len(combined):,} audio readings from {len(all_frames)} students\")\n",
    "    return len(combined)\n",
    "\n",
    "load_audio_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cba3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bluetooth data\n",
    "\n",
    "def load_bluetooth_data():\n",
    "    \"\"\"Load all bluetooth scan files\"\"\"\n",
    "    bt_dir = '/Users/test/Downloads/Data Management & Databases/studentlife_project/data/sensing/bluetooth'\n",
    "    all_frames = []\n",
    "    \n",
    "    for filename in os.listdir(bt_dir):\n",
    "        if not filename.endswith('.csv'):\n",
    "            continue\n",
    "        \n",
    "        uid = extract_uid(filename)\n",
    "        if not uid:\n",
    "            continue\n",
    "        \n",
    "        filepath = os.path.join(bt_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['uid'] = uid\n",
    "        \n",
    "        # Rename to match schema (MAC -> mac, etc.)\n",
    "        df = df.rename(columns={'MAC': 'mac'})\n",
    "        \n",
    "        all_frames.append(df)\n",
    "    \n",
    "    combined = pd.concat(all_frames, ignore_index=True)\n",
    "    combined.to_sql('bluetooth_scan', engine, if_exists='append', index=False)\n",
    "    \n",
    "    print(f\"✓ Loaded {len(combined):,} bluetooth scans from {len(all_frames)} students\")\n",
    "    return len(combined)\n",
    "\n",
    "load_bluetooth_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9189969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation data\n",
    "\n",
    "def load_conversation_data():\n",
    "    \"\"\"Load all conversation files\"\"\"\n",
    "    conv_dir = '/Users/test/Downloads/Data Management & Databases/studentlife_project/data/sensing/conversation'\n",
    "    all_frames = []\n",
    "    \n",
    "    for filename in os.listdir(conv_dir):\n",
    "        if not filename.endswith('.csv'):\n",
    "            continue\n",
    "        \n",
    "        uid = extract_uid(filename)\n",
    "        if not uid:\n",
    "            continue\n",
    "        \n",
    "        filepath = os.path.join(conv_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['uid'] = uid\n",
    "        \n",
    "        # Fix column names\n",
    "        df.columns = df.columns.str.strip()\n",
    "        df = df.rename(columns={\n",
    "            'start_timestamp': 'start_timestamp',\n",
    "            ' end_timestamp': 'end_timestamp'\n",
    "        })\n",
    "        \n",
    "        all_frames.append(df)\n",
    "    \n",
    "    combined = pd.concat(all_frames, ignore_index=True)\n",
    "    combined.to_sql('conversation', engine, if_exists='append', index=False)\n",
    "    \n",
    "    print(f\"✓ Loaded {len(combined):,} conversations from {len(all_frames)} students\")\n",
    "    return len(combined)\n",
    "\n",
    "load_conversation_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b822142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPS data\n",
    "\n",
    "def load_gps_data():\n",
    "    \"\"\"Load all GPS files\"\"\"\n",
    "    gps_dir = '/Users/test/Downloads/Data Management & Databases/studentlife_project/data/sensing/gps'\n",
    "    all_frames = []\n",
    "    \n",
    "    for filename in os.listdir(gps_dir):\n",
    "        if not filename.endswith('.csv'):\n",
    "            continue\n",
    "        \n",
    "        uid = extract_uid(filename)\n",
    "        if not uid:\n",
    "            continue\n",
    "        \n",
    "        filepath = os.path.join(gps_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['uid'] = uid\n",
    "        \n",
    "        all_frames.append(df)\n",
    "    \n",
    "    combined = pd.concat(all_frames, ignore_index=True)\n",
    "    combined.to_sql('gps_reading', engine, if_exists='append', index=False)\n",
    "    \n",
    "    print(f\"✓ Loaded {len(combined):,} GPS readings from {len(all_frames)} students\")\n",
    "    return len(combined)\n",
    "\n",
    "load_gps_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e33e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dark period data\n",
    "\n",
    "def load_dark_data():\n",
    "    \"\"\"Load all dark period files\"\"\"\n",
    "    dark_dir = '/Users/test/Downloads/Data Management & Databases/studentlife_project/data/sensing/dark'\n",
    "    all_frames = []\n",
    "    \n",
    "    for filename in os.listdir(dark_dir):\n",
    "        if not filename.endswith('.csv'):\n",
    "            continue\n",
    "        \n",
    "        uid = extract_uid(filename)\n",
    "        if not uid:\n",
    "            continue\n",
    "        \n",
    "        filepath = os.path.join(dark_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['uid'] = uid\n",
    "        \n",
    "        all_frames.append(df)\n",
    "    \n",
    "    combined = pd.concat(all_frames, ignore_index=True)\n",
    "    combined.to_sql('dark_period', engine, if_exists='append', index=False)\n",
    "    \n",
    "    print(f\"✓ Loaded {len(combined):,} dark periods from {len(all_frames)} students\")\n",
    "    return len(combined)\n",
    "\n",
    "load_dark_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0510cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phone charge data\n",
    "\n",
    "def load_phonecharge_data():\n",
    "    \"\"\"Load all phone charge files\"\"\"\n",
    "    charge_dir = '/Users/test/Downloads/Data Management & Databases/studentlife_project/data/sensing/phonecharge'\n",
    "    all_frames = []\n",
    "    \n",
    "    for filename in os.listdir(charge_dir):\n",
    "        if not filename.endswith('.csv'):\n",
    "            continue\n",
    "        \n",
    "        uid = extract_uid(filename)\n",
    "        if not uid:\n",
    "            continue\n",
    "        \n",
    "        filepath = os.path.join(charge_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['uid'] = uid\n",
    "        \n",
    "        all_frames.append(df)\n",
    "    \n",
    "    combined = pd.concat(all_frames, ignore_index=True)\n",
    "    combined.to_sql('phone_charge', engine, if_exists='append', index=False)\n",
    "    \n",
    "    print(f\"✓ Loaded {len(combined):,} phone charge periods from {len(all_frames)} students\")\n",
    "    return len(combined)\n",
    "\n",
    "load_phonecharge_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phone lock data\n",
    "\n",
    "def load_phonelock_data():\n",
    "    \"\"\"Load all phone lock files\"\"\"\n",
    "    lock_dir = '/Users/test/Downloads/Data Management & Databases/studentlife_project/data/sensing/phonelock'\n",
    "    all_frames = []\n",
    "    \n",
    "    for filename in os.listdir(lock_dir):\n",
    "        if not filename.endswith('.csv'):\n",
    "            continue\n",
    "        \n",
    "        uid = extract_uid(filename)\n",
    "        if not uid:\n",
    "            continue\n",
    "        \n",
    "        filepath = os.path.join(lock_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['uid'] = uid\n",
    "        \n",
    "        all_frames.append(df)\n",
    "    \n",
    "    combined = pd.concat(all_frames, ignore_index=True)\n",
    "    combined.to_sql('phone_lock', engine, if_exists='append', index=False)\n",
    "    \n",
    "    print(f\"✓ Loaded {len(combined):,} phone lock periods from {len(all_frames)} students\")\n",
    "    return len(combined)\n",
    "\n",
    "load_phonelock_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4313e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wifi data\n",
    "\n",
    "def load_wifi_data():\n",
    "    \"\"\"Load all WiFi scan files\"\"\"\n",
    "    wifi_dir = '/Users/test/Downloads/Data Management & Databases/studentlife_project/data/sensing/wifi'\n",
    "    all_frames = []\n",
    "    \n",
    "    for filename in os.listdir(wifi_dir):\n",
    "        if not filename.endswith('.csv'):\n",
    "            continue\n",
    "        \n",
    "        uid = extract_uid(filename)\n",
    "        if not uid:\n",
    "            continue\n",
    "        \n",
    "        filepath = os.path.join(wifi_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['uid'] = uid\n",
    "        \n",
    "        # Rename to match schema (BSSID -> bssid)\n",
    "        df = df.rename(columns={'BSSID': 'bssid'})\n",
    "        \n",
    "        all_frames.append(df)\n",
    "    \n",
    "    combined = pd.concat(all_frames, ignore_index=True)\n",
    "    combined.to_sql('wifi_scan', engine, if_exists='append', index=False)\n",
    "    \n",
    "    print(f\"✓ Loaded {len(combined):,} WiFi scans from {len(all_frames)} students\")\n",
    "    return len(combined)\n",
    "\n",
    "load_wifi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wifi location data\n",
    "\n",
    "def load_wifi_location_data():\n",
    "    \"\"\"Load all WiFi location files\"\"\"\n",
    "    wifiloc_dir = '/Users/test/Downloads/Data Management & Databases/studentlife_project/data/sensing/wifi_location'\n",
    "    all_frames = []\n",
    "    \n",
    "    for filename in os.listdir(wifiloc_dir):\n",
    "        if not filename.endswith('.csv'):\n",
    "            continue\n",
    "        \n",
    "        uid = extract_uid(filename)\n",
    "        if not uid:\n",
    "            continue\n",
    "        \n",
    "        filepath = os.path.join(wifiloc_dir, filename)\n",
    "        df = pd.read_csv(filepath)\n",
    "        df['uid'] = uid\n",
    "        \n",
    "        all_frames.append(df)\n",
    "    \n",
    "    combined = pd.concat(all_frames, ignore_index=True)\n",
    "    combined.to_sql('wifi_location', engine, if_exists='append', index=False)\n",
    "    \n",
    "    print(f\"✓ Loaded {len(combined):,} WiFi locations from {len(all_frames)} students\")\n",
    "    return len(combined)\n",
    "\n",
    "load_wifi_location_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c7275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"SENSING DATA LOAD COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nGo to DBeaver and check your tables!\")\n",
    "print(\"Try: SELECT COUNT(*) FROM activity_reading;\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
